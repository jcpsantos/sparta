:py:mod:`sparta.transformation`
===============================

.. py:module:: sparta.transformation


Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   sparta.transformation.drop_duplicates
   sparta.transformation.aggregation
   sparta.transformation.format_timestamp
   sparta.transformation.create_col_list
   sparta.transformation.typed_columns



.. py:function:: drop_duplicates(df: pyspark.sql.functions.DataFrame, col_order: str, cols_partition: List[Any]) -> pyspark.sql.functions.DataFrame

   Function that performs the deletion of duplicate data according to key columns.

   :param df: DataFrame.
   :type df: DataFrame
   :param col_order: Column to be used in sorting.
   :type col_order: str
   :param cols_partition: List of key columns, for partitioning.
   :type cols_partition: list

   :returns: DataFrame without the duplicate data, according to the key columns.
   :rtype: DataFrame

   .. rubric:: Example

   >>> cols = ['longitude','latitude']
   >>> df = drop_duplicates(df, 'population', cols)


.. py:function:: aggregation(df: pyspark.sql.functions.DataFrame, col_order: str, cols_partition: List[str], aggregations: Dict[Any, Any]) -> pyspark.sql.functions.DataFrame

   This function performs aggregations on columns.

   :param df: DataFrame.
   :type df: DataFrame
   :param col_order: Column to be used in sorting.
   :type col_order: str
   :param cols_partition: List of key columns, for partitioning.
   :type cols_partition: list
   :param aggregations: A dictionary with the columns and the type of aggregation that will be used. When the same type of aggregation occurs, a list with the column names must be passed.
   :type aggregations: dict

   :returns: DataFrame with aggregated columns.
   :rtype: DataFrame

   .. rubric:: Example

   >>> agg = {F.sum:'new_confirmed', F.first:'order_for_place'}
   >>> cols = ['state', 'city']
   >>> df = aggregation(df, 'date', cols, agg)

   When the same type of aggregation occurs on different columns.

   .. rubric:: Example

   >>> agg = {F.sum:['new_confirmed','order_for_place']}
   >>> cols = ['state', 'city']
   >>> df = aggregation(df, 'date', cols, agg)


.. py:function:: format_timestamp(df: pyspark.sql.functions.DataFrame, cols: List[str], timestamp: str = '"yyyy-MM-dd HH:mm:ss"') -> pyspark.sql.functions.DataFrame

   Function that performs a conversion from the date format to a pre-defined timestamp format.

   :param df: DataFrame.
   :type df: DataFrame
   :param cols: List of columns that will be converted.
   :type cols: list
   :param timestamp: Timestamp format. Defaults to '"yyyy-MM-dd HH:mm:ss"'.
   :type timestamp: _type_, optional

   :returns: DataFrame with the columns converted to a predefined timestamp format.
   :rtype: DataFrame

   .. rubric:: Example

   >>> df = format_timestamp(df, ['date'])


.. py:function:: create_col_list(df: pyspark.sql.functions.DataFrame, col: str) -> List[str]

   Function that creates a list with unique values from a column.

   :param df: DataFrame.
   :type df: DataFrame
   :param col: Column that will become a list.
   :type col: str

   :returns: A list of unique values for a given DataFrame column.
   :rtype: list

   .. rubric:: Example

   >>> create_col_list(df, 'city')


.. py:function:: typed_columns(df: pyspark.sql.functions.DataFrame, typecase: str = 'lower') -> pyspark.sql.functions.DataFrame

   Function that transforms DataFrame columns into lowercase or uppercase.

   :param df: DataFrame that will have the columns converted to lowercase or uppercase.
   :type df: DataFrame
   :param typecase: The column transformation type can be lower (lowercase) or upper (uppercase). Defaults to 'lower'.
   :type typecase: str, optional

   :raises ValueError: If the value of the typecase argument is not upper or lower.

   :returns: DataFrame with columns converted to lowercase or uppercase.
   :rtype: DataFrame

   .. rubric:: Example

   >>> typed_columns(df, 'upper')


